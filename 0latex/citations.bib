@article{Lillicrap2016DDPG,
  title={Continuous Control with Deep Reinforcement Learning},
  author={Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016},
  organization={Google Deepmind},
  address={London, UK}
}


@article{Hussein2011PIDGA,
  title={Proportional-Integral (PID) Controller Design Using Genetic Algorithm (GA)},
  author={Hussein, Emad A. and Waly, Musa H.},
  journal={Al-Qadisiya Journal For Engineering Sciences},
  year={2011},
  volume={4},
  number={2},
  organization={Electrical Engineering Department, Al-Mustansiriya University},
  address={Iraq-Baghdad}
}


@article{Agostinelli201XSystemCAMS,
  title={SystemC-AMS modeling and simulation of digitally controlled DC-DC converters},
  author={Agostinelli, Matteo and Priewasser, Robert and Huemer, Mario and Marsili, Stefano and Straeussnigg, Dietmar},
  journal={Unknown Journal},
  year={Unknown Year},
  organization={Networked and Embedded Systems – University of Klagenfurt, Infineon Technologies Austria AG},
  address={9020 Klagenfurt, Austria; 9500 Villach, Austria},
  email={Matteo.Agostinelli@uni-klu.ac.at, Stefano.Marsili@infineon.com}
}


@article{Luck2019ImprovedExploration,
  title={Improved Exploration through Latent Trajectory Optimization in Deep Deterministic Policy Gradient},
  author={Luck, Kevin Sebastian and Vecerik, Mel and Stepputtis, Simon and Ben Amor, Heni and Scholz, Jonathan},
  journal={arXiv preprint arXiv:1911.06833},
  year={2019},
  organization={Interactive Robotics Lab, Arizona State University; Google DeepMind},
  address={Tempe, AZ, USA; London, UK},
  email={{ksluck, sstepput, hbenamor}@asu.edu, {vec, jscholz}@google.com}
}



@article{Shi2020AdaptiveController,
  title={Adaptive Neuro-Fuzzy PID Controller based on Twin Delayed Deep Deterministic Policy Gradient Algorithm},
  author={Shi, Qian and Lam, Hak-Keung and Xuan, Chengbin and Chen, Ming},
  journal={Neurocomputing},
  year={2020},
  doi={https://doi.org/10.1016/j.neucom.2020.03.063},
  received={},
  revised={13 March 2020},
  accepted={21 March 2020},
  note={Journal Pre-proof, Communicated by Prof. Zidong Wang},
  email={qian.shi@kcl.ac.uk, hak-keung.lam@kcl.ac.uk, chengbin.xuan@kcl.ac.uk, ming.1.chen@kcl.ac.uk}
}


@article{Zhou2020DDPGPowerControl,
  title={Deep Deterministic Policy Gradient With Prioritized Sampling for Power Control},
  author={Zhou, Shiyang and Cheng, Yufan and Lei, Xia and Duan, Huanhuan},
  journal={National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China},
  year={Unknown Year},
  address={Chengdu 611731, China},
  email={chengyf@uestc.edu.cn},
  note={This work was supported in part by the National Nature Science Foundation of China under Grant U19B2014, in part by the National Key Research and Development Program of China under Grant 254, and in part by the Fund Project of the National Key Laboratory of Science and Technology on Communications under Grant 2102181402. Licensed under a Creative Commons Attribution 4.0 License},
  abstract={Reinforcement learning is a technique for power control in wireless communications. ... DDPG scheme with prioritized sampling (DDPG-PS) converges faster than the DDPG scheme with uniform sampling.},
  keywords={Power control, reinforcement learning, deep deterministic policy gradient, prioritized sampling, multiple sweep interference}
}


@article{WuXXXXAggregatedMultiDDPG,
  title={Aggregated Multi-deep Deterministic Policy Gradient for Self-driving Policy},
  author={Wu, Junta and Li, Huiyun},
  journal={Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences},
  year={Unknown Year},
  address={Shenzhen 518071, China},
  email={hy.li@siat.ac.cn},
  abstract={We present a deep reinforcement learning algorithm for control policies of self-driving vehicles. This method aggregates multiple sub-policies based on the deep deterministic policy gradient algorithm and centralized experience replays. ... This method outperforms the deep deterministic policy gradient algorithm with 56.7% less training time.},
  keywords={Self-driving, Deep reinforcement learning, Deep deterministic policy gradient}
}


@book{morales2020grokking,
    title = {Grokking Deep Reinforcement Learning},
    author = {Miguel Morales},
    year = {2020},
    month = {12},
    day = {05},
    foreword = {Charles Isbell, Jr.},
    publisher = {Manning Publications Co.},
    address = {20 Baldwin Road, PO Box 761, Shelter Island, NY 11964},
    edition = {},
    isbn = {},
    url = {https://www.manning.com}
}


@book{brunton2019data,
    title = {Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control},
    author = {Steven L. Brunton and J. Nathan Kutz},
    year = {2019},
    publisher = {Cambridge University Press},
    address = {University Printing House, Cambridge CB2 8BS, United Kingdom},
    edition = {},
    isbn = {978-1-108-42209-3},
    url = {https://www.cambridge.org/9781108422093},
    doi = {10.1017/9781108380690}
}


@article{Almawlawe2023,
  author    = {Muhanad D. Hashim Almawlawe and Muhammad Al-badri and Issam Hayder Alsakini},
  title     = {Performance Improvement of a DC/DC Converter Using Neural Network Controller in comparison with Different Controllers},
  journal   = {Unknown Journal},
  year      = {2023},
  volume    = {Unknown Volume},
  number    = {Unknown Number},
  pages     = {Unknown Pages},
  institution = {University of Al-Qadisiyah- Engineering College and Middle Technical University},
  email     = {muhanad.almawlawe@qu.edu.iq, muhanadhashim@gmail.com},
  abstract  = {Controlling a system is a complicated job, especially when we talk about the nonlinearity of the system introduced by the external changes. This paper presents the procedure of designing, analysis, and verification of nonlinear autoregressive moving average controller (NARMA L2) as an artificial intelligence technique to track the output voltage of a Buck dc/dc converter in comparison with PID controller, digitalized sliding mode controller so as to reduce the ripples in output voltage and to suppress the transient overshoots, or in other words, enhance the transient response diversity of the plant in the case of load and line changes. In this technique, a back- propagation learning algorithm is derived to increase the effectiveness of the proposed controller. Finally, the proposed method of control using a neural network controller is designed using MATLAB/SIMULINK and the results of the converter for the Neuro controller are compared with different techniques of control.}
}


@article{kulkarni_model-based_2023,
  title={Model-based Avionics Systems Fault Simulation and Detection},
  author={Kulkarni, Chetan and Biswas, Gautam and Kim, Kyusung and Bharadwaj, Raj Mohan},
  journal={[Journal Name - Not Provided]},
  year={2023},
  address={Nashville, TN and Golden Valley, MN},
  institution={Dept. of EECS/ISIS, Vanderbilt University and Honeywell Aerospace-Advance Technology},
  email={chetan.kulkarni, gautam.biswas@vanderbilt.edu, kyusung.kim, raj.bharadwaj@honeywell.com},
  abstract={This paper proposes a combined energy-based model with an empirical physics of failure model for degradation analysis and prognosis of electrolytic capacitors in DC-DC power converters. Electrolytic capacitors and MOSFET’s have higher failure rates than other components in DC-DC converter systems. ... using Monte Carlo simulation methods.},
  keywords={Bond Graphs, DC-DC converters, Electrolytic Capacitors, ESR, Fault Detection, Fault Isolation, GPS, Prognosis},
}


@book{wensdesign2022,
  title={Design and Implementation of Fully-Integrated Inductive DC-DC Converters in Standard CMOS},
  author={Wens, Mike and Steyaert, Michiel},
  publisher={[Publisher Name - Not Provided]},
  year={2022},
  address={Leuven, Belgium},
  series={Series Editors: Mohammed Ismail; Mohamad Sawan},
  note={ESAT-MICAS, Dept. Elektrotechniek, K.U. Leuven},
  email={Mike.Wens@esat.kuleuven.be; michiel.steyaert@esat.kuleuven.ac.be},
}


@article{jeong2023degradation,
  title={Degradation-Sensitive Control Algorithm Based on Phase Optimization for Interleaved DC–DC Converters},
  author={Jeong, Jaeyoon and Kwak, Sangshin and Choi, Seungdeog},
  journal={Machines},
  volume={11},
  pages={624},
  year={2023},
  publisher={MDPI},
  doi={10.3390/machines11060624},
  abstract={As the use of interleaved DC–DC converters in electric vehicles (EVs) increases, research on reliability improvement is required. ... its efficacy is proved through simulations and experiments.},
  keywords={silicon carbide MOSFET; degradation; 2-leg interleaved DC–DC boost converter; capacitor RMS current; phase optimization},
  note={Received: 1 May 2023, Revised: 29 May 2023, Accepted: 30 May 2023, Published: 5 June 2023},
  url={https://www.mdpi.com/journal/machines}
}
